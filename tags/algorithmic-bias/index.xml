<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>algorithmic bias on coletl</title>
    <link>https://coletl.github.io/tags/algorithmic-bias/</link>
    <description>Recent content in algorithmic bias on coletl</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&amp;copy; Cole Tanigawa-Lau 2022</copyright>
    <lastBuildDate>Wed, 31 Dec 1969 16:33:45 -0800</lastBuildDate><atom:link href="https://coletl.github.io/tags/algorithmic-bias/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Auditing the Audits</title>
      <link>https://coletl.github.io/research/audits/</link>
      <pubDate>Wed, 31 Dec 1969 16:33:45 -0800</pubDate>
      
      <guid>https://coletl.github.io/research/audits/</guid>
      <description>In this work, we “audit the audits,” analyzing the documents produced pursuant to one of the United States’ first enacted laws regulating the use of artificial intelligence in employment: New York City’s Local Law 144. This law requires employers and employment agencies using certain types of automated tools to publish “bias audits” with statistics about how different sex and racial groups fare in the hiring process when the tools are used.</description>
    </item>
    
  </channel>
</rss>
